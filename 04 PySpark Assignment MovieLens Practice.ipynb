{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from math import sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadMovieNames():\n",
    "    movieNames = {}\n",
    "    with open(\"/home/cloudera/Downloads/ml-100k/u.item\") as f:\n",
    "        for line in f:\n",
    "            fields = line.split('|')\n",
    "            movieNames[int(fields[0])] = fields[1].decode('ascii', 'ignore')\n",
    "    return movieNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makePairs((user, ratings)):\n",
    "    (movie1, rating1) = ratings[0]\n",
    "    (movie2, rating2) = ratings[1]\n",
    "    return ((movie1, movie2), (rating1, rating2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterDuplicates( (userID, ratings) ):\n",
    "    (movie1, rating1) = ratings[0]\n",
    "    (movie2, rating2) = ratings[1]\n",
    "    return movie1 < movie2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeCosineSimilarity(ratingPairs):\n",
    "    numPairs = 0\n",
    "    sum_xx = sum_yy = sum_xy = 0\n",
    "    for ratingX, ratingY in ratingPairs:\n",
    "        sum_xx += ratingX * ratingX\n",
    "        sum_yy += ratingY * ratingY\n",
    "        sum_xy += ratingX * ratingY\n",
    "        numPairs += 1\n",
    "\n",
    "    numerator = sum_xy\n",
    "    denominator = sqrt(sum_xx) * sqrt(sum_yy)\n",
    "\n",
    "    score = 0\n",
    "    if (denominator):\n",
    "        score = (numerator / (float(denominator)))\n",
    "\n",
    "    return (score, numPairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#conf = SparkConf().setMaster(\"local[*]\").setAppName(\"MovieSimilarities\")\n",
    "#sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading movie names...\n"
     ]
    }
   ],
   "source": [
    "print \"\\nLoading movie names...\"\n",
    "nameDict = loadMovieNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sc.textFile(\"file:/home/cloudera/Downloads/ml-100k/u.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map ratings to key / value pairs: user ID => movie ID, rating\n",
    "ratings = data.map(lambda l: l.split()).map(lambda l: (int(l[0]), (int(l[1]), float(l[2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(196, (242, 3.0)),\n",
       " (186, (302, 3.0)),\n",
       " (22, (377, 1.0)),\n",
       " (244, (51, 2.0)),\n",
       " (166, (346, 1.0)),\n",
       " (298, (474, 4.0)),\n",
       " (115, (265, 2.0)),\n",
       " (253, (465, 5.0)),\n",
       " (305, (451, 3.0)),\n",
       " (6, (86, 3.0))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Emit every movie rated together by the same user.\n",
    "# Self-join to find every combination.\n",
    "joinedRatings = ratings.join(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, ((292, 4.0), (292, 4.0))),\n",
       " (2, ((292, 4.0), (251, 5.0))),\n",
       " (2, ((292, 4.0), (50, 5.0))),\n",
       " (2, ((292, 4.0), (314, 1.0))),\n",
       " (2, ((292, 4.0), (297, 4.0))),\n",
       " (2, ((292, 4.0), (290, 3.0))),\n",
       " (2, ((292, 4.0), (312, 3.0))),\n",
       " (2, ((292, 4.0), (281, 3.0))),\n",
       " (2, ((292, 4.0), (13, 4.0))),\n",
       " (2, ((292, 4.0), (280, 3.0))),\n",
       " (2, ((292, 4.0), (303, 4.0))),\n",
       " (2, ((292, 4.0), (308, 3.0))),\n",
       " (2, ((292, 4.0), (307, 3.0))),\n",
       " (2, ((292, 4.0), (257, 4.0))),\n",
       " (2, ((292, 4.0), (316, 5.0))),\n",
       " (2, ((292, 4.0), (315, 1.0))),\n",
       " (2, ((292, 4.0), (301, 4.0))),\n",
       " (2, ((292, 4.0), (313, 5.0))),\n",
       " (2, ((292, 4.0), (279, 4.0))),\n",
       " (2, ((292, 4.0), (299, 4.0)))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinedRatings.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# At this point our RDD consists of userID => ((movieID, rating), (movieID, rating))\n",
    "# Filter out duplicate pairs\n",
    "uniqueJoinedRatings = joinedRatings.filter(filterDuplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, ((292, 4.0), (314, 1.0))),\n",
       " (2, ((292, 4.0), (297, 4.0))),\n",
       " (2, ((292, 4.0), (312, 3.0))),\n",
       " (2, ((292, 4.0), (303, 4.0))),\n",
       " (2, ((292, 4.0), (308, 3.0))),\n",
       " (2, ((292, 4.0), (307, 3.0))),\n",
       " (2, ((292, 4.0), (316, 5.0))),\n",
       " (2, ((292, 4.0), (315, 1.0))),\n",
       " (2, ((292, 4.0), (301, 4.0))),\n",
       " (2, ((292, 4.0), (313, 5.0)))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueJoinedRatings.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now key by (movie1, movie2) pairs.\n",
    "moviePairs = uniqueJoinedRatings.map(makePairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((292, 314), (4.0, 1.0)),\n",
       " ((292, 297), (4.0, 4.0)),\n",
       " ((292, 312), (4.0, 3.0)),\n",
       " ((292, 303), (4.0, 4.0)),\n",
       " ((292, 308), (4.0, 3.0)),\n",
       " ((292, 307), (4.0, 3.0)),\n",
       " ((292, 316), (4.0, 5.0)),\n",
       " ((292, 315), (4.0, 1.0)),\n",
       " ((292, 301), (4.0, 4.0)),\n",
       " ((292, 313), (4.0, 5.0)),\n",
       " ((292, 299), (4.0, 4.0)),\n",
       " ((292, 298), (4.0, 3.0)),\n",
       " ((292, 295), (4.0, 4.0)),\n",
       " ((292, 305), (4.0, 3.0)),\n",
       " ((292, 293), (4.0, 4.0)),\n",
       " ((292, 294), (4.0, 1.0)),\n",
       " ((292, 310), (4.0, 4.0)),\n",
       " ((292, 309), (4.0, 1.0)),\n",
       " ((292, 306), (4.0, 4.0)),\n",
       " ((292, 311), (4.0, 5.0))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviePairs.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We now have (movie1, movie2) => (rating1, rating2)\n",
    "# Now collect all ratings for each movie pair and compute similarity\n",
    "moviePairRatings = moviePairs.groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((505, 1131), <pyspark.resultiterable.ResultIterable at 0x7fe1b1677c50>),\n",
       " ((218, 1664), <pyspark.resultiterable.ResultIterable at 0x7fe1b1677e10>),\n",
       " ((388, 846), <pyspark.resultiterable.ResultIterable at 0x7fe1b1677e50>),\n",
       " ((320, 652), <pyspark.resultiterable.ResultIterable at 0x7fe1b1677e90>),\n",
       " ((1038, 1132), <pyspark.resultiterable.ResultIterable at 0x7fe1b1677ed0>),\n",
       " ((490, 1108), <pyspark.resultiterable.ResultIterable at 0x7fe1b1677f10>),\n",
       " ((1062, 1110), <pyspark.resultiterable.ResultIterable at 0x7fe1b1677f50>),\n",
       " ((681, 1669), <pyspark.resultiterable.ResultIterable at 0x7fe1b1677f90>),\n",
       " ((293, 759), <pyspark.resultiterable.ResultIterable at 0x7fe1b1677fd0>),\n",
       " ((114, 404), <pyspark.resultiterable.ResultIterable at 0x7fe1b167d050>),\n",
       " ((1058, 1568), <pyspark.resultiterable.ResultIterable at 0x7fe1b167d090>),\n",
       " ((142, 996), <pyspark.resultiterable.ResultIterable at 0x7fe1b167d0d0>),\n",
       " ((440, 1084), <pyspark.resultiterable.ResultIterable at 0x7fe1b167d110>),\n",
       " ((330, 588), <pyspark.resultiterable.ResultIterable at 0x7fe1b167d150>),\n",
       " ((419, 917), <pyspark.resultiterable.ResultIterable at 0x7fe1b167d190>),\n",
       " ((1439, 1561), <pyspark.resultiterable.ResultIterable at 0x7fe1b167d1d0>),\n",
       " ((56, 468), <pyspark.resultiterable.ResultIterable at 0x7fe1b167d210>),\n",
       " ((4, 924), <pyspark.resultiterable.ResultIterable at 0x7fe1b167d250>),\n",
       " ((49, 261), <pyspark.resultiterable.ResultIterable at 0x7fe1b167d290>),\n",
       " ((906, 1648), <pyspark.resultiterable.ResultIterable at 0x7fe1b167d2d0>)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviePairRatings.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We now have (movie1, movie2) = > (rating1, rating2), (rating1, rating2) ...\n",
    "# Can now compute similarities.\n",
    "moviePairSimilarities = moviePairRatings.mapValues(computeCosineSimilarity).cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the results if desired\n",
    "#moviePairSimilarities.sortByKey()\n",
    "#moviePairSimilarities.saveAsTextFile(\"movie-sims\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 similar movies for Outbreak (1995)\n",
      "Crimson Tide (1995)\tscore: 0.976323576179\tstrength: 68\n",
      "Time to Kill, A (1996)\tscore: 0.976199912697\tstrength: 57\n",
      "Ransom (1996)\tscore: 0.972265504235\tstrength: 67\n",
      "In the Line of Fire (1993)\tscore: 0.971513119024\tstrength: 61\n"
     ]
    }
   ],
   "source": [
    "sys.argv[1] = 54\n",
    "if (len(sys.argv) > 1):\n",
    "\n",
    "    scoreThreshold = 0.97\n",
    "    coOccurenceThreshold = 50\n",
    "\n",
    "    movieID = int(sys.argv[1])\n",
    "\n",
    "    # Filter for movies with this sim that are \"good\" as defined by\n",
    "    # our quality thresholds above\n",
    "    filteredResults = moviePairSimilarities.filter(lambda((pair,sim)): \\\n",
    "        (pair[0] == movieID or pair[1] == movieID) \\\n",
    "        and sim[0] > scoreThreshold and sim[1] > coOccurenceThreshold)\n",
    "\n",
    "    # Sort by quality score.\n",
    "    results = filteredResults.map(lambda((pair,sim)): (sim, pair)).sortByKey(ascending = False).take(10)\n",
    "\n",
    "    print \"Top 10 similar movies for \" + nameDict[movieID]\n",
    "    for result in results:\n",
    "        (sim, pair) = result\n",
    "        # Display the similarity result that isn't the movie we're looking at\n",
    "        similarMovieID = pair[0]\n",
    "        if (similarMovieID == movieID):\n",
    "            similarMovieID = pair[1]\n",
    "        print nameDict[similarMovieID] + \"\\tscore: \" + str(sim[0]) + \"\\tstrength: \" + str(sim[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
